{"eval_exact_match": 70.66666666666667, "eval_f1": 80.20410330410333, "eval_bleu": {"bleu": 0.4608013297396644, "precisions": [0.634765625, 0.5248618784530387, 0.41015625, 0.3299492385786802], "brevity_penalty": 1.0, "length_ratio": 1.656957928802589, "translation_length": 512, "reference_length": 309}}