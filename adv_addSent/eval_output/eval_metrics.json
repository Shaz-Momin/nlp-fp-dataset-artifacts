{"eval_exact_match": 34.666666666666664, "eval_f1": 41.92101572293388, "eval_bleu": {"bleu": 0.43525975054887955, "precisions": [0.48905109489051096, 0.4482758620689655, 0.4235294117647059, 0.3865546218487395], "brevity_penalty": 1.0, "length_ratio": 1.0703125, "translation_length": 411, "reference_length": 384}}