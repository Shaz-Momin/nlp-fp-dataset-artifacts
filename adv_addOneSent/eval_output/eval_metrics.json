{"eval_exact_match": 35.44303797468354, "eval_f1": 43.19375324396486, "eval_bleu": {"bleu": 0.377851123326964, "precisions": [0.44844124700239807, 0.40540540540540543, 0.36363636363636365, 0.30833333333333335], "brevity_penalty": 1.0, "length_ratio": 1.2264705882352942, "translation_length": 417, "reference_length": 340}}