{"eval_exact_match": 36.666666666666664, "eval_f1": 44.007416182029175, "eval_bleu": {"bleu": 0.5592300802768505, "precisions": [0.5437665782493368, 0.5462555066079295, 0.5777777777777777, 0.5698924731182796], "brevity_penalty": 1.0, "length_ratio": 1.0802292263610316, "translation_length": 377, "reference_length": 349}}